[{"categories":["VPN"],"content":"What is a VPN in the first place? VPN is what it says: Virtual Private Network. but what does that exactly mean?\nSuppose you are using an internet connection available at your university and connecting to the internet. In this case, the university has a private network setup that allows you to access the internet, but here, You can definitely get traced because, well, ultimately, the traffic will be coming and going to your university\u0026rsquo;s main router, and of course, the ISP has records for that. and your university might as well keep records of what you are visiting through a firewall, which is a common scenario.\nBut with the VPN, you can get into a private network, but in this case, it is virtual in some other geographical region, which keeps your identity private (mostly!) Here, it is very hard to trace your identity and what you have visited when you are visiting a VPN.\nIf you are accessing a VPN at your university, the university will find a normal valid IP address that you are visiting, but mostly it doesn\u0026rsquo;t know it is a VPN and has no control over what you are accessing or how you are accessing it.\nIt is like you are virtually in that private network, i.e., your PC or laptop is in the private network, which is on some server that you don\u0026rsquo;t handle.\nFine, now that you understand how VPN works, let\u0026rsquo;s understand how AWS allows you to create a VPN and let you connect to it.\nWhen creating a VPN in AWS, you can do the following:\naccess private resources not routable on the internet. e.g., not having public IP. access internet securely to access some content that is restricted to your geographical location. have controlled connectivity for VPN clients to be able to access the internet. Only allow connectivity from your VPN for a particular resource and not from the internet, though the resources are publicly available. e.g., having administrative privileges work only when admins are connected via VPN and not exposing the admin API over the internet. etc. There are more use cases, of course, than this. But you get the point.\nWell, let\u0026rsquo;s dive deep into how everything fits together. When you need to create a VPN, what you are basically doing is creating a VPN service, which will let users connect to it. you can,\nrestrict which users can access the VPN using mutual authentication. restrict users over subnets and internet connectivity. VPN is, of course, over HTTPS, so who is going to provide the secure connection?\nVPN is a kind of lightweight service that listens to client connection requests and, based on the required authentication, lets users connect to it.\nBut to provide a secure connection, you need an SSL certificate, right?\nYou can request a certificate from the AWS certificate manager, but wait, should you do it?\nRequesting a certificate from the AWS Cert Manager will authorize a certificate for a domain. Supposing you have bought the example.com domain, setup static hosting on the S3 bucket, and want to secure your client connections, you request a certificate from Cert Manager. where you prove your domain ownership. So then you can use that certificate in CloudFront to secure your domain.\nBut here is the catch: your clients can get the secure connection when they connect to your domain, which you have validated when requesting the certificate, right?\nBut when you create a VPN client in AWS that has a different endpoint, something like,\ncvpn-endpoint-06cfc1ca6ccea985c.prod.clientvpn.us-east-1.amazonaws.com This is the endpoint that I got when I created a client VPN.\nSo, how do you handle this domain? Is there any point in requesting a certificate from AWS for this domain? Of course not!\nWhat you simply need to do is create a custom certificate and sign it with a certificate authority of your own!\nCreate client and server certificates on your Linux machine. To create client and server certificates, you must have a certificate authority that signs those certificates, right?\nHere understand that we need to have mutual authentication, meaning we also need to authorize the clients that are connecting to the VPN and allow only them to connect.\nsteps are taken from the AWS VPN Guide\nClone the OpenVPN easy-rsa repo to your local computer and navigate to the easy-rsa/easyrsa3 folder. git clone https://github.com/OpenVPN/easy-rsa.git this provides an easy workflow for creating and managing certificates.\nInitialize a new PKI environment. ./easyrsa init-pki To build a new certificate authority (CA), run this command and follow the prompts. ./easyrsa build-ca nopass no pass means you don\u0026rsquo;t require a passphrase to use that ca-certificate. Basically, you are creating \u0026lsquo;ca-cert\u0026rsquo;, which will act as the root certificate and \u0026lsquo;private key\u0026rsquo; for that certificate.\nGenerate the server certificate and key. ./easyrsa build-server-full server nopass This creates a server certificate and its private key. Here, a certificate gets created, which means it is also signed by the certificate authority by using its private key.\nNow you can optionally generate client certificates. This means that you can generate a separate certificate for each client or use the same for everyone. However, it is recommended that you use a separate certificate for each client, so in the case of that employee leaves your organization, you can simply revoke that certificate, rather than revoking the common one and giving everyone a new cert.\nBut for our usecase one cert is enough. so let\u0026rsquo;s go ahead and create it.\nGenerate the client certificate and key. ./easyrsa build-client-full client1.domain.tld nopass Copy the server certificate and key and the client certificate and key to a custom folder, and then navigate into the custom folder. mkdir ~/custom_folder/ cp pki/ca.crt ~/custom_folder/ cp pki/issued/server.crt ~/custom_folder/ cp pki/private/server.key ~/custom_folder/ cp pki/issued/client1.domain.tld.crt ~/custom_folder cp pki/private/client1.domain.tld.key ~/custom_folder/ cd ~/custom_folder/ This is to simplify the workflow for uploading these certs to AWS.\nUploading certificates to the AWS Certificate Manager Here, you can either use aws-cli or aws-console to upload the certificates.\nBut we will follow a console-based method for simplicity.\nHead towards AWS Certificate Manager and click import Certificate.\nHere, give the details, like server certificate, Private Key and optionally the certificate chain. But here, you must provide the certificate of CA.\nIf you don\u0026rsquo;t provide a CA certificate, even in normal cases of simply attaching to a domain, your client browser will request a certificate, and when it gets this, it will try to authorize it with the built-in CA certificates that it trusts. If it doesn\u0026rsquo;t find any CA certificates that can authorize this server certificate, It fails to authorize it and doesn\u0026rsquo;t set up TLS.\nBut when you also provide the CA certificate along with the server certificate, the client can authorize it and establish the secure connection, but of course, it will try to back out as the certificate is custom and not globally accredited.\nBut in our case for VPN connections, this is fine and the recommended way of managing certificates.\nSo when the client connects, it will be able to authorize the server using the CA cert and successfully establish a connection to the server via TLS.\nNow, when you provide the CA cert in the certificate chain, of course you have only two hierarchies in the certificate chain: one is the server cert, and the other is the root cert, or CA cert, which actually signs the server cert.\nSo you simply need to give the CA certificate in the certificate chain.\nNow your certificate is imported! Congrats!\nNow you can optionally import the client certificate here. But in our case, it is not required. Why?\nBecause when our VPN service requests that the client bring its own certificate and the client sends it, The VPN service authorizes it on the basis of a certificate chain, right? But if the client doesn\u0026rsquo;t send the CA cert, then how does this service authorize it? Well, it falls back on using the certificate chain provided by us for the server.\nAnd as we have created the client certificate and signed it using the same CA authority The service will successfully be able to authorize the client certificate.\nBut if you have used different CA, you need to import exactly the same you imported the server cert.\nThis also proves security. why?\nBecause no one can use any certificate other than signed by your CA authority, which is residing in your linux machine!\nSo even if a person has globally accredited certificate for his server, his of-course won\u0026rsquo;t be able to access our VPN service as the server would fail to authorize it as its certificate is not signed by our CA Authority\nCreating a Client VPN Endpoint This step actually creates a VPN where users can connect.\nHere, go to the Client VPN Endpoints section in the VPC.\nCreate an Endpoint.\nHere, give,\nname for the endpoint (optional) Give the CIDR block from which your clients will get private IP addresses. Don\u0026rsquo;t give a CIDR block, which can conflict with the subnet that you want to work with. Give server certificate that will be used for a secure connection. Check the mutual authentication box to authorize clients as well. Here for Client Certificate ARN, choose the same server certificate. This makes sure that the VPN service will authorize the clients based on the CA cert of the server itself. i.e it will use the certificate chain of server certificate to authorize the client certificate. If you have used different CA for client certificate, make sure to import that first and choose it. You can optionally set the DNS server to use here. remember there is no default DNS server configured for your VPN, so if you plan to access internet from this, make sure to add DNS server here. Leave everything blank, as we don\u0026rsquo;t require other things for this demonstration.\nNow you have set up the client VPN. Its now time to give clients access to a particular subnet or subnets.\nTo configure this, simply go to the target network associations\nand then choose Associate target network\nHere, choose the subnet that you want to access from your VPN.\nThere is a route table associated with this VPN, and when you associate the subnet, It automatically creates an entry in the route table.\nHere, you can also add custom route entries, like for accessing the internet.\nBut remember, you can only access the internet with the help of a subnet.\nSo if you have configured the Internet Gateway for that VPC, you can go on the internet from the VPN. when you add 0.0.0.0/0 route in the route table and select the target network as the subnet that has internet access.\nHere, remember that, by-default, VPN configures NAT by which you can reach the internet, so even if the subnet doesn\u0026rsquo;t have access to the internet, if an internet gateway is there, you can access the internet from the VPN without any extra configuration. That\u0026rsquo;s great!\nBut small things are remaining that you need to do in order to fully set up your VPN.\nFirst, head towards Authorization Rules and create the rule where all or some of your clients are able to access what they want.\nIf you want to allow all the clients to go wherever they need to go according to the route table, simply Allow them for the 0.0.0.0/0 network.\nThese rules allow you to give fine-grained access to your VPN clients, so even if the route table of the VPN has multiple routes, it is your responsibility to give each client specific access or give all of them full access to all the networks (subnets) that you have associated.\nTesting Now that everything is setup, try creating an EC2 instance in the same region as your VPN and making it private purposefully. Also, make sure to create it in the subnet that you have associated with the VPN.\nNow you can\u0026rsquo;t access this instance from the internet, right? And before this, there was no way with which you could gain access to this instance, right?\nMeaning if you headed towards Connect and tried connecting, AWS would error out that the instance is private.\nIn order to connect to it, there was only one way there: bastion host, which is again not that secure considering you still require a public endpoint from which you will access private resources.\nBut now, with the Client VPN, you can successfully access the instance as the subnet in which it lies is associated with the VPN.\nSo download the client configuration from the top bar.\nYou get an .ovpn file.\nBefore you start using it, a few changes are required.\nThe changes are because, if you didn\u0026rsquo;t setup mutual authentication for VPN, you can use this file directly to connect to the VPN.\nBut as you have mutual authentication enabled, you need to provide the certificate path and private key path in this .ovpn file.\nSo before changes, the file looks like this:\nclient dev tun proto udp remote cvpn-endpoint-00e16cdbf058cc151.prod.clientvpn.us-east-1.amazonaws.com 443 remote-random-hostname resolv-retry infinite nobind remote-cert-tls server cipher AES-256-GCM verb 3 \u0026lt;ca\u0026gt; -----BEGIN CERTIFICATE----- \u0026lt;the certificate here\u0026gt; -----END CERTIFICATE----- \u0026lt;/ca\u0026gt; reneg-sec 0 verify-x509-name server name Here, you don\u0026rsquo;t see any configuration for the client certificate or its private key.\nNow, as I previously told you, store all the files in custom_folder, including the client certificate and its private key. Grab their fully qualified path and paste it like this, so the end result is like,\nclient dev tun proto udp remote cvpn-endpoint-00e16cdbf058cc151.prod.clientvpn.us-east-1.amazonaws.com 443 remote-random-hostname resolv-retry infinite nobind remote-cert-tls server cipher AES-256-GCM --cert \u0026#34;/home/varad/custom_folder/client.domain.tld.crt\u0026#34; --key \u0026#34;/home/varad/custom_folder/client.domain.tld.key\u0026#34; verb 3 \u0026lt;ca\u0026gt; -----BEGIN CERTIFICATE----- \u0026lt;the certificate here\u0026gt; -----END CERTIFICATE----- \u0026lt;/ca\u0026gt; reneg-sec 0 verify-x509-name server name See those --cert and --key, and paste your paths in front of them.\nNow when that is done, it\u0026rsquo;s done!\nYou cannot use the aws-cli for connecting to this VPN.\nSo now head over to the aws vpn client download to download the appropriate client for your system with which you can connect to the VPN you just set up.\nI prefer the windows/macos client as for Linux, you require outdated Linux machines (18.04 \u0026amp; 20.04) and I bet most of you people won\u0026rsquo;t even have it. And don\u0026rsquo;t even try to download this client in a suitable Docker container or VM, as this might cause unnecessary troubles. (I tried a lot.)\nSo if you have a Windows client, make sure to change the path in the certificate accordingly and have double backslashes instead of singles in the path.\nNow, after all this, you can now successfully connect to the VPN!\n","permalink":"https://belwalkarvarad.tech/posts/vpn-workflow-aws/","summary":"Setting VPN in AWS is not straightforward!","title":"How to actually setup VPN in AWS?"},{"categories":["S3","AWS"],"content":"S3 buckets are somewhat like google drive storages.\nHere, S3 is an object storage, meaning simply you store files and folders under a bucket, and that is all, hence it is also called as flat storage, as it doesn\u0026rsquo;t involve any file system.\nHere is an overview of S3 storage given by network kings:\nSo when you are going to create an S3 bucket,\nthe S3 bucket name you create need to be globally unique, yes you heard it right, else you cannot create it. Also it needs to be in lowercase.\nNext, you choose the region in which to create the bucket, an defaultely, the bucket as shown in above diagram, get backed up as per AWS rules, into 3 or more availability zones. You don\u0026rsquo;t manage this replication, as amazon does this internally.\nNext, By default Block all Public Access is selected, meaning that no one can access the objects stored inside this bucket unless you configure manually.\nHere, there are two things as per the S3 bucket object, the bucket URI and URL, URI simply identifies it, while teh URL actually locates it so that you can view or download it.\nBut, as mentioned above, if the bucket ACL is to block all public access, no one can view it using hte URL right, then how does it look like when we try to view it?\nFirst this is a typical object overview:\nAnd this is shown when we try to access this particular object, i.e access denied.\nAgain before deleting the bucket, you need to empty it first, and then delete it, delete the versions as well if you have enabled versioning\n","permalink":"https://belwalkarvarad.tech/posts/s3-bucket-aws-overview/","summary":"An overview of S3 bucket in AWS","title":"An overview of S3 bucket in AWS"},{"categories":["API","REST","HTTP"],"content":"HTTP API vs REST API HTTP API (Application Programming Interface) and REST API (Representational State Transfer API) are terms frequently used in the context of web development to describe different approaches to building and consuming APIs. While HTTP is a protocol that defines how data is transmitted over the web, REST is an architectural style that uses HTTP as its communication protocol. Let\u0026rsquo;s explore the differences between HTTP API and REST API:\nDefinitions: HTTP API:\nBroad term referring to any API that uses the HTTP protocol for communication. Doesn\u0026rsquo;t prescribe a specific architectural style or set of constraints. REST API:\nAn architectural style defining a set of constraints and principles for creating web services. RESTful APIs conform to principles like statelessness, resource-based architecture, and a uniform interface. Architectural Style: HTTP API:\nCan follow any architectural style, not necessarily adhering to REST principles. Examples include SOAP (Simple Object Access Protocol), GraphQL, or some other custom style. REST API:\nAdheres to REST principles, including statelessness, resource identification through URIs, a uniform interface, and representation of resources in standard formats like JSON or XML. Statelessness: HTTP API:\nMay or may not be stateless. State is managed by the application or the client; each request contains all information needed. REST API:\nEmphasizes statelessness. Each request must contain all information needed, and the server should not store any state about the client between requests. Uniform Interface: HTTP API:\nDoes not necessarily enforce a uniform interface; endpoints and methods can vary between different APIs. REST API:\nEnforces a uniform interface, using standard HTTP methods (GET, POST, PUT, DELETE) and consistent naming conventions for resources. Data Format: HTTP API:\nCan use various data formats, including XML, JSON, or others, for communication. REST API:\nTypically uses standard data formats like JSON or XML for representing resources. Flexibility: HTTP API:\nOffers flexibility in design and implementation; may not strictly adhere to any particular set of principles. REST API:\nProvides a more structured and standardized approach, promoting principles for scalability, simplicity, and statelessness. In summary, while HTTP API is a generic term referring to any API using the HTTP protocol, REST API specifically adheres to the principles of the REST architectural style, providing a standardized and structured approach to web service design.\n","permalink":"https://belwalkarvarad.tech/posts/http-vs-rest-api/","summary":"Know the difference!","title":"HTTP vs REST API"},{"categories":["AWS","Networking"],"content":"AWS Peering Connection: Simplified VPC Networking Overview AWS Peering Connection facilitates easy VPC connectivity, allowing seamless communication between VPCs across accounts and regions.\nConnection Scenarios You can establish connections between VPCs in the following scenarios:\nSame account, same region Same account, different regions Different account, same region Different account, different region Setup Process Requester and Accepter Roles:\nThe requester initiates the connection. The accepter responds to the request. Network Requirements:\nBoth VPCs must have different network configurations. Connection Setup:\nChoose the requester VPC ID. Specify if the accepter is in the same account and region. Provide the accepter\u0026rsquo;s account ID and region if different. Enter the accepter VPC ID. Connection Management For same-account connections, go to the Peering Connection dashboard and accept the connection. For different-account connections, the accepter manages the connection in their account. Additional Steps After creating the connection, update route tables in both VPCs to ensure seamless traffic flow. Specify the destination network and designate the Peering Connection as the gateway in route table configurations. Conclusion AWS Peering Connection streamlines VPC networking, allowing for efficient communication between VPCs in various scenarios.\n","permalink":"https://belwalkarvarad.tech/posts/peering-connection-in-aws/","summary":"Peering Connections in AWS","title":"What is Peering Connections in AWS?"},{"categories":["VPCs","AWS"],"content":"To Understand the Concept of VPC in detail, visit my in detail visualisation here\nPlease understand that, above visualisation holds perfect for every aspect of designing and creating solutions, but not necessarily the same scenario exists in the real world as per AWS implementation, but the underlying concept remains same, so don\u0026rsquo;y worry about implementation details, the visualisation holds true, which is better for understanding why we are creating so much things to get things done!\nFirst we will talk about the custom VPC here, so then explaining the default VPC becomes easier. So, When you create a custom VPC, you create that VPC in a region right, lets say N. Virginia, which is us-east-1 You only create a VPC, and not any subnets. So lets say you created VPC 10.10.10.0/24 Unless you create the subnets, you cannot create instances here.\nSo you first create subnet/s, and preference to zones is your choice.\nHere, when you create a VPC, defaultely a routing table i.e the main route table gets created for that VPC, and as you go creating the subnets, that table gets associated to the container in that subnet(as per in diagram)\nSo, here you don\u0026rsquo;t need to associate this route table to any subnet, as it is associated by default\nBut when you create custom route table, you associate it to a subnet, and its gets replaced with the original present there in the container\nHere, according to the workflow, when you create custom VPC and a main route table, the main route table only contains private route entry.\nSo when you create the subnet, you have option to say yes to auto-assign public ip addresses, So this actually creates a static NAT in the container, which in turn when assigned ip address to an instance, creates entry to map private ip to a public ip.\nBut when you create the VPC, create the subnet, say yes to auto-assign public ip, this all is not enough as you are not connected to gateway yet (as explained in diagram)\nSo first you need to create Internet Gateway, and associate it with the VPC, so that all subnets are associated with the Internet Gateway in their respective availability zones.\nHere, as per in diagram only then the link gets created between your container and the actual Gateway in the zone.\nIs this enough to get Internet Connectivity?\nBecause you got the public ip address to the instance right?\nNo, because the main route table still doesn\u0026rsquo;t contain the entry that we want.\nthe entry is\nDestination Gateway 0.0.0.0/0 \u0026lt;Select Gateway You Created\u0026gt; This now makes sure that your traffic will reach the internet and vice versa.\nWhen you say no to the auto-assign public ip in the create subnet section, you can still assign a particular instance a public ip by first creating elastic ip in the elastic ip section and then associating that ip to the instance. But they need to be in the same availability zone.\nOnce you associate public ip to the instance, the container associated with that subnet makes entry in the static NAT for the private ip, to get associated with the chosen public ip, so that you can then be able to reach on internet and again, vice versa\nYou can also do PAT (Port address Translation), but the thing is you create PAT service by going into NAT gateways section, and creating a NAT gateway!\nI know this might sound weird but it is as it is!\nWhen you create a NAT gateway, you have option to assign the public IP on the fly or choose the available IP from elastic IPs you reserved.\nWell when you are creating a NAT gateway, you need to give in which subnet you want to create it, so that it goes in that particular container, but it doesn\u0026rsquo;t automatically start doing PAT.\nHere, understand that, even if you create this NAT device in a particular subnet, it doesn\u0026rsquo;t mean that other subnets can\u0026rsquo;t use it.\nSuppose you want to use the NAT Gateway for the same subnet as your NAT device is,\nSo you simply add the following Entry in your routing table,\nDestination Gateway 0.0.0.0/0 \u0026lt;Your NAT Gateway (NOT internet gateway) \u0026gt; So there be come the NAT gateway option, and you simply select it, and now your subnet traffic will get PATTED.\nBut suppose you want to also utilize this NAT device for another subnet, well you can do that. Simply do the same as above to the routing table of that particular subnet, here you need to create custom routing table for that subnet, as without which you will configure the main route table and thus each subnet will use this unnecessarily.\nHere, You can also let only specific services to be accessible on the internet for speicifc users in specific subnets by using this NAT table, by configuring custom route tables, How cool is this!\nHere understand that this NAT gateway is like a device, which actually gets a private IP in the associated subnet, and does the necessary stuff.\nBut of course, you will create this NAT gateway in the subnet where you want to actually use it right? As latency will be minimum.\nBut here is a catch!\nLets say you created a NAT and attached to a subnet, and after that created custom route table, made 0.0.0.0/0 go towards this device, so that the the instances in this subnet are able to access the internet, but the thing is, how will you check this?\nWell here you can create a public instance, in another subnet, yes you heard it right, because if you create an instance in the same subnet where the NAT is configured to do PAT as per route table for that subnet, and attach a public ip to it with elastic ip, the thing is the public ip is of no use, as the NAT device will override this and make your instance basically private, meaning that the configuration in the container is initially the public ip to private ip mapping for the instance, but now you also have the NAT configured where the route table targets that, so the problem is, your traffic will go from the container as if it is public, but when it reaches the NAT device, it will take it and do PAT, and now your public ip existance has gone,\nSo the public ip is of no use, and you cannot access this instance even if public ip is showing associated with it.\nSo the only way is run this instance in another subnet,\nOR\nYou can configure the route table to route to the internet gateway instead of the NAT gateway for that particular ip of the public instance So this will also work.\nNow comes the info about Security groups.\nThere is always a default security group, which lets all traffic to outbound from instance, but no inbound, so you cannot access the instance even if you got public ip, so when you create instance, you have option to choose the security group or create one, by default create security group is selected and services mentioned there which you allow inbound traffic for.\nBut if you select the default one, you can no longer connect to the instance, as explained above.\nSo you can go to the security groups, and create a security group which tells what can inbound and outbound, and then you can choose this while creating the instance, which makes sense.\nYou can also update the security group while the instance is using it, and the changes will be immediate.\nNow in the case of defaultVPC, the thing is, it is created by default in all AWS regions, with subnets precreated in all availability zones for you.\nYou also get a default Internet Gateway precreated, and also that Internet Gateway is associated with the defaultVPC, so that all your subnets can reach to the internet,\nand by default, all the subnets auto-assign public ip to the instances, i.e defaultely perform static NAT from private to public and vice versa\nAnd also the main route table contains entry\nDestination Gateway 0.0.0.0/0 \u0026lt;precreated Gateway\u0026gt; This makes sure that the instances are able to reach the internet and vice versa.\n","permalink":"https://belwalkarvarad.tech/posts/aws-vpc-workflow/","summary":"A detailed explaination regarding VPCs in AWS","title":"What are custom VPCs in AWS?"},{"categories":["VPCs","AWS"],"content":"Understanding AWS Default VPC and Public Subnets You might be wondering why the default VPC is called a public subnet if it is a private network, right? Let\u0026rsquo;s start from the beginning!\nWhen you are in an AWS region, you are given a default VPC. This default VPC is unique to your AWS account, and other accounts get their own default VPCs. The private networks, represented by IP range 172.31.0.0/16, are only accessible to you.\nEach AWS account gets this private network (172.31.0.0/16) in each region, with subnetting performed. Each availability zone (AZ) becomes a subnet, and while the specifics might vary by region, the concept remains the same.\nPublic Subnet Naming Now, the question arises: If these are private networks or subnets within an AZ, why does AWS refer to them as public subnets?\nThe answer lies in how you access the internet. In the common scenario, internet access is achieved through Network Address Translation (NAT), typically done by your Internet Service Provider (ISP). You can find a detailed explanation in this repository.\nAlternatively, you can obtain a public IP, eliminating the need for NAT, allowing the internet to reach your instance without any problem.\nPublic IP in Default VPC When you create an instance in the default VPC (i.e., 172.31.0.0/16), you get two IP addresses. One is, of course, from the private network, and the other is a public IP address. For example, you might get 172.31.0.1/16 and 3.4.5.6/something (the public IP depends on AWS).\nHere, AWS owns and maintains a public subnet infrastructure to provide IP addresses to instances and possibly containers created in the default VPC. Remember, this behavior is specific to the default VPC.\nDefault VPC Instances Accessibility So, even if your instance has a private IP, it also comes with a public IP by default. This means your instance is publicly accessible without any NAT configuration.\nAs you create more instances, all of them will get public IPs by default, effectively contributing to a public subnet for your default VPC.\nContrast with Custom VPCs When you create another VPC, you don\u0026rsquo;t get public IPs by default. Typically, it is considered a private subnet, meaning the internet can\u0026rsquo;t reach your instances without performing NAT. AWS handles this NAT process.\nIn the default VPC, AWS configures your VPC with a default gateway for your instances. This gateway has rules to forward all traffic (0.0.0.0/0) to its gateway if the private network doesn\u0026rsquo;t match.\nYou can configure this gateway and change the default forwarding behavior. AWS also configures DHCP in your default VPC, automatically assigning private IP addresses — remember, only private ones, as public IPs are managed by AWS.\n","permalink":"https://belwalkarvarad.tech/posts/defaultvpc-workflow/","summary":"A detailed explaination regarding defaultVPC in AWS","title":"What is defaultVPC in AWS?"},{"categories":["VPCs","AWS"],"content":"Domain Registration Setting up a website isn\u0026rsquo;t that easy when you want complete control over hosting of your website. For example, to setup application server, or to setup your own static hosted server\n","permalink":"https://belwalkarvarad.tech/posts/domain-registration/","summary":"domain registration","title":"What happens when you register a domain?"},{"categories":["Linux","Networking"],"content":"Here, when we install docker on our machine, docker creates a virtual interface, which is then assigned with an ip address from a predefined pirvate n/w range,\nand there exists a virtual switch between the virtual interface and the interfaces of containers, so that all those interfaces are in the same network.\nHowever this virtual switch is not visible.\nScenario is,\nTypical Scenario But When you create a bridge using the command,\nip link add my-bridge type bridge You are actually creating a virtual switch, and not virtual interface, and when you run this command,\nip link set eth0 master my-bridge You are actually assigning the eth0 interface as the interface of the virtual switch itself.\nBefore this, your normal eth0 interface would drop the frames which are not intended for it (normally),\nbut when you master it over the switch, as per the policy of switch, its work is simple, forward to it right interface according to the dest. MAC,\nand when a frame comes from the eth0 interface, its work is simple, forward it to appropriate interface, in this case, the interfaces of the switch are of-course virtual.\nHere, main thing is that, this switch(bridge), is visible and thus, its intefaces as well, meaning that as shown below, the interfaces of this switch, you can\nsee in the output of the ip link command.\nSo meaning that each interface of this switch will be listed with its output, and meaning that each interface is connected to one docker container.\nSo if you run 100 containers, hundred virtual interfaces will be created which will be part of this switch.\nBridged Scenario Here, after seeing this diagram, it might be clear for you that why host is unable to connect to network and internet.\nThe problem is,\nWhen you add the interface to the bridge, it becomes interface of the virtual switch, and hence virtual switch is the one who controls it now.\nMeaning that, the host needs to move its entire TCP/IP stack from the eth0 interface to some other one which actually has connectivity.\nTo do so, as shown above, we create another port on virtual switch named host port,\nand most importantly, create a virtual interface called my-bridge, which is then connected to this host port,\nand then when we run the\ndhcpcd my-bridge\ncommand, we are actually assigning ip address to this virtual interface and thus getting connection from there, as shown in above diagram.\nSo, this means that, when you run the command,\nip link add my-bridge type bridge You are actually creating this my-bridge interface, and connecting this interface to the this virual switch! And this is what docker exactly does!\nWhen docker creates the docker0 interface, it simply does this, so that this interface is now connected to the virtual switch, and then the\ncontainers are getting connected, so complete private network, where host is able to connect to the containers from this docker0 interface, and so the containers, and via host routing, able to reach to the internet.\nThe thing comes when we want to have what i previously mentioned, networking on host network,\nSo as mentioned in the diagram above, only thing comes in mind is somehow make the eth0 port as port of switch, so that all the traffic can be\nintercepted on this port, and thus allowing to extend the actual host network, making it look like the containers are on the host network itself.\nFollow this link to know more about the context:\nhttps://superuser.com/q/1815441/1723212\n","permalink":"https://belwalkarvarad.tech/posts/linux-virtual-interfaces/","summary":"Linux Virtual Interface Creation and its Working","title":"Linux Virtual Interfaces"},{"categories":["windows"],"content":"The art of engineering WSL2 The reason why you can run powershell.exe from WSL 2 is because WSL 2 supports running Windows executables directly from the Linux command line. This is a feature of the WSL 2 architecture, which allows the Linux kernel to communicate with the Windows host through a special interface called 9P. 9P is a network protocol that enables file system and network operations to be performed across the virtual machine boundary.\nWhen you run a Windows executable from WSL 2, such as powershell.exe, the following steps happen:\nWSL 2 checks if the executable has the .exe extension and is on the PATH environment variable. If not, it returns an error message. WSL 2 invokes the /init binary, which is the provisional binfmt_misc “interpreter” for the Windows executables. binfmt_misc is a Linux facility that allows launching binaries with arbitrary formats /init creates a new process on the Windows host using the CreateProcess API, and passes the executable name and arguments to it The Windows executable runs on the Windows host, and its standard input, output, and error streams are redirected to the WSL 2 terminal This way, you can run Windows tools directly from the WSL 2 command line using [tool-name].exe. For example, notepad.exe. Applications run this way have the following properties:\nRetain the working directory as the WSL 2 command prompt (for the most part – exceptions are explained below). Have the same permission rights as the WSL 2 process. ","permalink":"https://belwalkarvarad.tech/posts/the-art-of-engineering-wsl2/","summary":"Why I like WSL-2 so much!","title":"The Art of engineering WSL-2"},{"categories":["Apache","Webserver"],"content":"Virtual hosting in Apache2 refers to the capability of the Apache web server to host multiple websites on a single server. This allows a single physical server to serve content for multiple domains or hostnames, providing a cost-effective and resource-efficient solution. There are two main types of virtual hosting in Apache2: Name-based virtual hosting and IP-based virtual hosting.\nName-Based Virtual Hosting: Configuration Files: In Apache2, virtual hosting is configured through the Apache configuration files, typically found in the sites-available directory. Each virtual host is defined in a separate configuration file, often named after the domain it serves (e.g., example.com.conf).\nDNS Configuration: The DNS records for each domain must be configured to point to the IP address of the Apache server. Apache uses the Host header from the HTTP request to determine which virtual host should handle the request. Apache Configuration Example:\n\u0026lt;VirtualHost *:80\u0026gt; ServerName www.example.com DocumentRoot /var/www/example.com \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost *:80\u0026gt; ServerName www.anotherexample.com DocumentRoot /var/www/anotherexample.com \u0026lt;/VirtualHost\u0026gt; Here instead, you can specify the server name in the place of * sign. Meaning instead of *:80 you can specify example.com:80 in the first and anotherexample.com:80 in the second configuration.\nWildcard and Default Virtual Hosts: Wildcard virtual hosts can be used to match multiple subdomains (e.g., *.example.com). A default virtual host can be configured to handle requests that do not match any specified virtual hosts.\nIP-Based Virtual Hosting: Configuration with IP Addresses: In IP-based virtual hosting, each virtual host is associated with a specific IP address. This method is necessary when the server has multiple IP addresses.\nApache Configuration Example:\n\u0026lt;VirtualHost 192.168.1.1:80\u0026gt; ServerName www.example.com DocumentRoot /var/www/example.com \u0026lt;/VirtualHost\u0026gt; \u0026lt;VirtualHost 192.168.1.2:80\u0026gt; ServerName www.anotherexample.com DocumentRoot /var/www/anotherexample.com \u0026lt;/VirtualHost\u0026gt; Additional Considerations: SSL/TLS Virtual Hosting: For secure connections (HTTPS), additional configurations for SSL/TLS virtual hosting are required. This involves specifying SSL certificates and configuring the virtual host for port 443.\nLog Files: Each virtual host can have its own access and error log files, making it easier to track and analyze traffic for specific domains.\nSecurity: Proper permissions and security measures should be implemented to prevent one virtual host from affecting others.\nReload or Restart: After making changes to virtual host configurations, Apache must be reloaded or restarted for the changes to take effect (sudo service apache2 reload or sudo service apache2 restart).\n","permalink":"https://belwalkarvarad.tech/posts/virtual-hosting-apache/","summary":"Host multiple websites using apache","title":"Virtual Hosting through Apache"},{"categories":["LXC","LXD"],"content":"First in case you messed up with the lxd by creating cluster,and now you are unable to access the lxd daemon,\nbecause your IP has changed,\nIf you don\u0026rsquo;t have any critical information stored in any of the lxd instances, you can simply remove all the files, under,\n/var/snap/lxd/common/lxd/database/ by running,\nsudo rm -rf /var/snap/lxd/common/lxd/database/* And thereafter running lxd init again to configure new workflow.\nCommands List remote repositories that make images available:\nlxc remote list And to see which images are available on a particular remote repository:\nlxc image list \u0026lt;remote_name\u0026gt;: e.g lxc image list images: Copy the image from the remote repository to local\nThe only way to pull images to local repo is to copy from remote end.\nlxc image copy images:ubuntu/22.04/amd64 local: --alias ubuntu Launch a container from image, pull image if not exists:\nlxc launch ubuntu container-name Creating a New Container:\nlxc init ubuntu my-container Starting a Container:\nlxc start my-container Stopping a Container:\nlxc stop my-container Delete a container:\nlxc delete container-name List storage pools(You can\u0026rsquo;t run anything if there is no storage pool, as it doesn\u0026rsquo;t create automatically like docker does)\nlxc storage list Create a storage pool to be used by containers/vms:\nHere, the preferred storage driver in my case is dir, others are btrfs etc.\nlxc storage create storage-name dir source=/var/snap/lxd/common/lxc/storage-pools/storage-name To launch or init a container in a particular storage pool:\nlxc launch ubuntu container-name -s mystoragepool lxc init ubuntu container-name -s mystoragepool Make sure that you have freshly created pool, otherwise this won\u0026rsquo;t work, or the pool which is empty. Before you make any storage pool default for a profile(default is default), the profile looks like:\nconfig: {} description: Default LXD profile devices: {} name: default used_by: [] and after change it will look like this:\nconfig: {} description: Default LXD profile devices: root: path: / pool: local type: disk name: default used_by: [] So to configure the default storage for this profile, i.e to change the pool, you can either do it manually, by looking at the end result as above:\nlxc profile edit default and then change the pool name to the name that you want as default pool, while the path mentioned there is nothing but, relative path against the pool configured, so if storage pool you are using here is /var/snap/lxd/common/lxd/storage-pools/local then the path is considered as root i.e /, meaning that if you configure path to be /containers, then the containers that you create using this profile, in term, using this default storage pool, the actual container directory will be created at /var/snap/lxd/common/lxd/storage-pools/local/containers/\u0026lt;container-name\u0026gt; location.\nAs you can see above, there is no entry in the device section, so first we need to add a device called root so that it will used by default, and set it params, this is recommended way rather than editing the file manually,\nlxc profile device add default root disk pool=local path=/ Here we are addding the device called root to the default profile and setting the pool to local, and path to / here. Here the type of device(root) is disk.\nBut if you have already the root device over there, simply edit its configuration if not suitable.\nThe recommended way to change this config is,\nlxc profile device set default root pool=\u0026lt;pool_name\u0026gt; Here, we are editing profile, so the lxc profile command,\nnext, we want to edit the devices section, so the device set,\nnext, the profile default one,\npool next, root means the device we want to configure and pool=\u0026lt;pool_name\u0026gt; means we are changing/adding that property.\nAccessing a Container\u0026rsquo;s Console:\nlxc console my-container This is similar to getting a shell in the container with the exec command, but requires password for the user already set up.\nExecuting a Command Inside a Container:\nlxc exec my-container ls -l Adding a repository to the remote list:\nlxc remote add --protocol simplestreams ubuntu https://cloud-images.ubuntu.com/releases/ configure a vm/container:\nlxc config edit vm/container Creating Snapshots:\nlxc snapshot my-container snapshot-1 Restoring from a Snapshot:\nlxc restore my-container snapshot-1 Copying and Moving Containers:\nlxc copy my-container my-container-copy lxc move my-container my-container-renamed Listing Containers:\nlxc list Displaying Container Information:\nlxc info my-container Configuring Container Properties:\nlxc config set my-container limits.cpu 2 Creating a Bridge Network:\nlxc network create my-network Adding a Container to a Network:\nlxc network attach my-network my-container Listing LXD Networks:\nlxc network list Deleting a Network:\nlxc network delete my-network Cloning a Container:\nlxc copy my-container my-container-clone Exporting a Container:\nlxc publish my-container --alias my-container-image Importing an Exported Container:\nlxc image import my-container-image.tar.gz --alias my-container-image Uploading Files to a Container:\nlxc file push /path/to/local/file my-container/root/path/in/container/ Downloading Files from a Container:\nlxc file pull my-container/root/path/in/container/file /path/to/local/destination/ Simply add a recursive flag -r in case it is a directory.\nListing Snapshots:\nlxc info my-container Deleting Snapshots:\nlxc delete my-container/snapshot-name Renaming a Container:\nlxc rename my-container new-container-name Connecting to a Remote LXD Host:\nlxc remote add remote-name remote-host Managing Containers on a Remote Host:\nlxc remote list lxc remote show remote-name lxc remote remove remote-name Monitoring Container Resource Usage:\nlxc monitor --type=container my-container Creating a Container from an Image:\nlxc init my-custom-image my-new-container Exporting a Custom Image:\nlxc image export my-custom-image my-custom-image.tar.gz Moving Containers to Different Storage Pools:\nlxc move my-container my-new-container --target new-storage-pool Container Configuration Overrides:\nlxc config set my-container limits.memory 2GB lxc config unset my-container limits.memory Creating a Custom Bridge Network:\nlxc network create my-custom-bridge ipv4.address=192.168.1.1/24 ipv4.nat=true Assign a specific IP address to a container.\nlxc config device add my-container eth0 nic nictype=bridged parent=my-custom-bridge name=eth0 ipv4.address=192.168.1.2 Running a Container in Privileged Mode:\nlxc config set my-container security.privileged true lxc start my-container Creating a Container Backup:\nlxc export my-container /path/to/backup-directory Restoring a Container from Backup:\nlxc image import /path/to/backup-file --alias my-restored-container lxc init my-restored-container my-restored-container-name Listing Available Images on a Remote Server:\nlxc remote list my-remote-server lxc image list my-remote-server: ","permalink":"https://belwalkarvarad.tech/posts/lxc-commands-list/","summary":"LXC Commands list with explaination","title":"Understand LXC commands "},{"categories":["MySQL"],"content":"Understanding MySQL Authentication MySQL authentication can be intricate, especially when running scripts or programmatically connecting to the MySQL instance. The complexity arises from MySQL\u0026rsquo;s use of authentication plugins to verify the user interacting with the MySQL daemon.\nAuthentication Plugin Challenges When using MySQL with sudo privileges:\nsudo mysql Being a superuser grants direct access to the root account without requesting a password. However, attempting to log in manually without sudo:\nmysql Results in a permission denied error. Even providing the correct password for the root account:\nmysql -u root -p Leads to permission denied issues. This is because the default authentication mechanism for the root account is set to auth_socket (Unix socket). Consequently, accessing /var/run/mysql.sock is necessary for authentication, which normal user can\u0026rsquo;t.\nAuthentication Plugin Switch To resolve this challenge, change the authentication plugin to mysql_native_password. This plugin authenticates based on the password, independent of machine privileges or local/remote execution.\nNow, you can successfully execute:\nmysql -u root -p Simply provide the password, and access is granted. This solution also ensures remote or programmatic interactions work seamlessly.\nChecking and Updating Authentication Plugin To check the current authentication plugin:\nSELECT user, host, plugin FROM mysql.user WHERE user = \u0026#39;root\u0026#39;; If the plugin is set to auth_socket or unix_socket, it implies root user authentication relies on system credentials. To enable password-based authentication, update the plugin:\nALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;new_password\u0026#39;; After updating the authentication plugin, reload the grant tables and apply the changes:\nFLUSH PRIVILEGES; This approach ensures a smooth MySQL authentication experience, making it accessible via various methods while maintaining security measures.\n","permalink":"https://belwalkarvarad.tech/posts/mysql-authentication/","summary":"intricacies of MySQL authentication","title":"How does MySQL authenticates users?"},{"categories":["MySQL"],"content":"Select all fields from table customers SELECT * FROM customers; Select Specific Columns from a Table SELECT name, email FROM customers; Alias Columns SELECT name AS customer_name, email AS customer_email FROM customers; Select Distinct Values SELECT DISTINCT country FROM customers; here there will not be any duplicate entry for what you chosen, remember for what you chosen i.e for only the fields you considered, of course this would not do anything when you choose all the fields as that would be an entire tuple which will always be unique\nLimit the Number of Rows Returned SELECT name, email FROM customers LIMIT 10; This is mostly used with the ORDER BY in order to get First X tuples according to sorting\nSort the Result Set SELECT name, email FROM customers ORDER BY name ASC; (DESC for descending) Filter Rows with WHERE Clause SELECT name, email FROM customers WHERE country = \u0026#39;USA\u0026#39;; Here understand that the priority of WHERE clause is MAX and thus,\nthe mysql selects only those tuples which satisfy the criteria rather than applying filter afterwards Here the mysql goes tuple by tuple and sees first if the tuple is matching the criteria if given then actually considers the fields to be selected\nUse Logical Operators in WHERE Clause SELECT name, email FROM customers WHERE age \u0026gt;= 18 AND city = \u0026#39;New York\u0026#39;; (Here you can use OR as well and also IN operator) Aggregate Functions (e.g., COUNT, SUM, AVG) SELECT COUNT(*) FROM customers; here COUNT is an aggregate function in SQL, where * defines which columns to choose, abviously, you can give any field name here as it won\u0026rsquo;t affect the result It is similar to having something like this: SELECT * FROM customers \u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; COUNT Remember COUNT only counts the tuples i.e number of results\nSELECT name, COUNT(*) FROM customers; In MySQL, when iterating through the table and matching WHERE criteria, the required field (e.g., name) is appended to a result table. Since there\u0026rsquo;s no GROUP BY, the COUNTER in the result table is simply incremented for each matching tuple. After all tuples are processed, and at least one field is selected, MySQL creates a final result table by combining the first tuple with the single COUNTER value, providing the result with fields like name and COUNT(*) or names.\nSELECT AVG(age) FROM customers WHERE country = \u0026#39;USA\u0026#39;; Here the AVG is again an aggregate function which finds average of given field, here becomes important aspect It is similar to SELECT age FROM customers WHERE country = \u0026lsquo;USA\u0026rsquo; \u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; AVG Here the AVG function is getting tuples containing only one field i.e age, so it is easy for it to calculate average and return it\nSELECT SUM(quantity) FROM sales; Here the SUM is an aggregate just like the AVG but instead of calculating the average it simply sums up the result It is like, SELECT quantity FROM sales \u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; SUM Here it gets the tuples just containing quantity as the field and then the SUM just sums it up\nGrouping and Aggregation (e.g., GROUP BY, HAVING) SELECT country, COUNT(*) as customer_count FROM customers GROUP BY country HAVING customer_count \u0026gt; 5; In MySQL with the GROUP BY clause, the engine iterates through the table, appending required fields to a result table based on grouping criteria. Each tuple in the result table has a separate counter. If a tuple with a country already in the result table is encountered, the counter is incremented. After processing all tuples, MySQL returns distinct names with counters.\nNote: GROUP BY doesn\u0026rsquo;t require the selected field (e.g., country) in the result table; it can have other criteria like company. MySQL creates a virtual entry for grouping.\nThe HAVING clause, unlike WHERE, filters the result table based on aggregate functions. Use HAVING for filtering with aggregate functions.\nSubqueries SELECT name, email FROM customers WHERE country IN (SELECT country FROM suppliers WHERE category = \u0026#39;Electronics\u0026#39;); SUM up the fields SELECT column1 + column2 AS total_sum FROM table_name; SELECT distinct values SELECT DISTINCT column_name FROM table_name; LIKE operator SELECT column1 FROM table_name WHERE column2 LIKE \u0026#39;%pattern%\u0026#39;; MIN MAX aggregators SELECT MIN(column1), MAX(column2) FROM table_name; here the workflow is same, what mysql does is makes two field result table here, and then starts iterating through tuples when tuple matches the criteria, if the result table is empty, the respective fields are written as it is in the fields i.e MIN(column1) and MAX(column2) but when a tuple satisfies criteria, and mysql sees already entered value/s in the result table, it then takes the value/s from the tuple and then compares it with one present in the result table, according to MIN and MAX, it then decides whether to update it or not\nJOIN SELECT table1.column, table2.column FROM table1 JOIN table2 ON table1.id = table2.id; ","permalink":"https://belwalkarvarad.tech/posts/mysql-select/","summary":"Select Query","title":"MySQL Select Query"},{"categories":["Linux","iptables"],"content":"NAT Table Overview This is my NAT table from the iptables command, specifically in the netfilter.\nChain PREROUTING (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- anywhere anywhere ADDRTYPE match dst-type LOCAL Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination 1 DOCKER all -- anywhere !127.0.0.0/8 ADDRTYPE match dst-type LOCAL Chain POSTROUTING (policy ACCEPT) num target prot opt source destination 1 MASQUERADE all -- 172.17.0.0/16 anywhere Chain DOCKER (2 references) num target prot opt source destination 1 RETURN all -- anywhere anywhere Chain PREROUTING This chain is responsible for packets as they arrive on the network interface before any routing decisions are made. In this specific case, there is one rule:\nRule 1:\nIt matches all packets with the destination address being the local machine (ADDRTYPE match dst-type LOCAL) and forwards them to the DOCKER chain. This rule is often used by Docker to handle incoming packets to its containers. Chain INPUT The INPUT chain is responsible for packets destined for the local system (the Linux machine itself). In this case, there are no specific rules, so all incoming packets will be allowed (policy ACCEPT). If there were specific rules, they would be listed here.\nChain OUTPUT The OUTPUT chain handles locally generated packets on the Linux system. There is one rule:\nRule 1:\nIt matches all packets with the destination address not in the 127.0.0.0/8 range (meaning packets not destined for localhost) and forwards them to the DOCKER chain. This is often used by Docker for its networking setup. Chain POSTROUTING The POSTROUTING chain handles packets after routing decisions have been made and just before they are sent out on the network interface. There is one rule:\nRule 1:\nIt performs source NAT (SNAT) using MASQUERADE for packets coming from the 172.17.0.0/16 subnet. MASQUERADE means that the source IP address of outgoing packets will be replaced with the IP address of the outgoing interface (dynamic NAT). This is commonly used in Docker networking to allow containers to communicate with the external network using the host\u0026rsquo;s IP address. Chain DOCKER The DOCKER chain is used by Docker to apply its own network rules. It is being referenced by rules in both the PREROUTING and OUTPUT chains.\nRule 1:\nThe RETURN target means that if a packet reaches this rule, it will continue processing in the original chain (either PREROUTING or OUTPUT) without further actions from this chain. In other words, this rule effectively allows packets to continue through the chain without any modifications. Please note that the order of the rules matters in the chains. When a packet arrives or leaves the system, it is processed sequentially through the rules in each applicable chain until it matches a rule that either accepts, rejects, or modifies the packet. The first matching rule determines the fate of the packet. If no rule matches, the policy defined for the chain is applied (ACCEPT in this case).\n","permalink":"https://belwalkarvarad.tech/posts/iptables-nat-table-overview/","summary":"Linux NAT table overview","title":"Linux NAT table overview"},{"categories":["Nodejs"],"content":"One of the most useful package in NodeJS is a package called n. Yes you heard it right it has name n\nHOW TO INSTALL?\nnpm install -g n HOW TO USE?\nsudo n \u0026lt;version_to_use\u0026gt; Here if the proposed version is not present, it will download it and switch to it then.\n","permalink":"https://belwalkarvarad.tech/posts/nodejs-n-package/","summary":"Version switching in nodejs","title":"How to switch between different Nodejs versions?"},{"categories":["VLAN","Networking"],"content":"VLAN are inevitable in today\u0026rsquo;s world for the companies, why? Before answering why, let me tell what does VLAN mean in the first place,\nwell, you know that in large corporate network, suppose you are network engineer and your company has bought some ranged ip network, and suppose in particular section, you have performed NAT to avoid incoming connections hit the private network,\nAnd in this private network, you have around 1k devices such as media computers, sales computers, and marketing teams\u0026rsquo; computers, also you have servers which need a lot protection which are internal servers not intended for the outside world,\nand as you can guess, the public ip range the company has bought is to provide services externally through some other partial network, and this private network is intended to be used only for accessing internet and doing internal company\u0026rsquo;s work,\nas here are around 1k devices and suppose from them you have 10 servers which needed to be more secure, but you think that these are in private network and are safe, but not they are not, unless all the other devices in the network are safe\nhere, you might think that VLAN is not actually solution but we can do subnetting for the private network and assign the network range to internal computers which are then connected with the switch right,\nwell this approach has a problem, when you supppose assign first subnet to computers which don\u0026rsquo;t have do anything with the servers, then you can configure firewall on the router outgrowing into the servers\u0026rsquo; network to even block the private range which is for those computers,\nbut let me tell you, routers are not cheap, they are pretty expensive than switches, yes that is the problem,\nand if you have to subnet a lot of times i.e subnet into more smaller and smaller group of computers and servers, that is not a viable option, as you have to invest in both routers and switches as well,\nAnd this is also not going to work if you want some computers but not all from a particular subnet to access the servers in another subnet, how do you configure the router for that, you might say well by only allowing particular ip addresses right,\nwell those computers are getting ips from DHCP, so your method of allowing only some ips doesn\u0026rsquo;t work here right,\nwell you might also say that the broadcast domain is also not violeted here, as the subnet, that is the broadcast network right,\nbut let me tell you, suppose again some computers from one subnet need to talk to some computers from another subnet but to not all, and vice versa, are you going to again to firewalling over there for just these pcs, and again setting up firewall here, to not allow certain traffic to certain computers?\nhere you just not only need to indentify the traffic\u0026rsquo;s network, but also need to configure individual ips to allow or block traffic to certain pcs in the network, this is rediculous and time consuming and not scalable and if you are allocating ips with DHCP, then it is going to be really hard,\nSo what is the solution? The solution is really simple, it is not only cost effective, only requires switches and not routers, and also minimizes broadcast domains and also help us to talk certain pcs to only certain pcs and not all,\nit is VLAN,\nThe VLAN feature is available in almost all layer 2 switches and of course in all layer 3 switches as well, but we only focus on layer 2 switches as we don\u0026rsquo;t require layer 3 switches in most cases.\nTo really connect the entire LAN of 1k devices, you suppose might need 80 switches, as in above scenario with subnetting you would require not only 80 switches but also more routers along with that with so much tedious task\nwell you just require layer 2 switches and just connect them to each other with their interfaces,\nso that all the computers and servers and all are in the same network, and as of now they can talk to each other,\nnow its your time to simply put the interfaces of the switch into appropriate VLANs and you have to do it in all the switches (normally) so that the computer connected to an interface of switch which is in VLAN2 can only talk to computers or servers which are connected to interfaces of switches which are in VLAN 2 only, and thus, the broadcast domain is minimised as you broadcast request/response will not go to all the devices but to only devices which are part of the same VLAN.\nHere, first understand that if you don\u0026rsquo;t configure VLANs at all, all the devices are in VLAN 1 by default, so they can talk to each,\nwhen you put interfaces in appropriate VLANs, you also need to put the interfaces which are connecting two switches together into Trunking, which means that they now can follow 802.1q protocol which allows padding the frame with VLAN information so that other switch can know that the frame coming is from which VLAN,\nof course, the switch can absolutely know its interfaces are in which VLAN, the the frame coming from other switch, this switch will not know the computer with this MAC address is in which VLAN as it obviously doesn\u0026rsquo;t know on which interface it is connected as that is not its interface right, of course i know that the switches doesn\u0026rsquo;t consider the MAC to interface mapping to determine which VLAN the frame belongs to, as they simply identify the frames are in which VLAN by simply seeing from which interface they are coming from and that interface belongs to which VLAN,\nand for sending, now it checks the MAC to interface binding and checking to which VLAN that interface belongs to and to send it or not,\nso how does the next switch will know the traffic generated from switch one, is from which VLAN, as it doesn\u0026rsquo;t know the VLAN configuration of that switch of course,\nso this is the reason for using the trunking protocol on the both the interfaces, where the switches understand that 802.1q protocol which contains VLAN information which is of 4 bytes, so a 1514 bytes frame would become 1518 bytes\nBut you need to make sure that the, negotiation of trunking is off,\notherwise if you make your computer\u0026rsquo;s interface as trunk port/interface using tools like yersinia, the negotiation of trunking if on, the interface of the switch will recognise this trunk port and will become trunk port/interface itself, and this is the problem,\nnow you are not in any VLAN, as the ports/interface which are trunks are not in any VLAN, as they are required to provide VLAN info to other switches, but how does this switch know that i am not a switch but an infected or malicious computer which is trying to access other VLANs\nas here i can simply substitute the frame going outwords with the VLAN i want to access, and the switch will not complain as it doesn\u0026rsquo;t know me i.e it doesn\u0026rsquo;t have my MAC address mapped to any interface as the interface i am connected to is trunk port, and trunk ports though are mapped to multiple MAC addresses, but they are not in any VLAN right, so the switch thinks that there is only one computer connected to the switch on the other side of its trunk port/interface so simply maps my MAC to the trunk port but solely relies on the stuffed VLAN info in the frame as of course it cannot assign VLAN to the trunk port as the traffic coming from the other switch can be for same or different VLAN of course!\nso the negotiation of trunking must be off so that even if my computer pretends that its interface if trunked, the switch will NOT move to make its interface to be trunked as well, so this will not happen,\nso the only option to configure the interface as trunk is to manually go or access the switch remotely and configure the interface through CLI, and thats it!\nThis solves the broadcast domain problem as the switch will only forward the broadcast frame to the interface belonging to the same VLAN else not.\nSo even if a computer got infected or attacked by an attacker, it cannot simply use tools like yersinia to do trunking and access any VLAN\nThis is called the VLAN hopping attack and the negotiation of trunking to be made off to prevent this attack.\n","permalink":"https://belwalkarvarad.tech/posts/what-is-vlan/","summary":"VLAN deepdive","title":"What is VLAN?"},{"categories":["windows","Networking"],"content":"netsh is primarily used for configuring network and network interfaces Show available interface\nnetsh interface show interface Disable Network interfaces\nnetsh interface set interface \u0026#34;Ethernet\u0026#34; admin=disable Enable Network interfaces\nnetsh interface set interface \u0026#34;Ethernet\u0026#34; admin=enable Manually assign ip address to interface\nnetsh interface ipv4 set address \u0026#34;Ethernet\u0026#34; static 192.168.1.100 255.255.255.0 Default Gatway configuration\nnetsh interface ipv4 set address \u0026#34;InterfaceName\u0026#34; static IPAddress SubnetMask DefaultGateway To set DNS servers for the interface, use the following command. Replace \u0026ldquo;DNSserver1\u0026rdquo; and \u0026ldquo;DNSserver2\u0026rdquo; with the actual IP addresses of the DNS servers:\nnetsh interface ipv4 set dns \u0026#34;InterfaceName\u0026#34; static DNSserver1 primary netsh interface ipv4 add dns \u0026#34;InterfaceName\u0026#34; DNSserver2 index=2 To show available WIFI Access Points\nnetsh wlan show networks ","permalink":"https://belwalkarvarad.tech/posts/netsh-in-windows/","summary":"learn netsh","title":"netsh in windows"},{"categories":["Linux"],"content":"A setuid binary, also known as a set-user-ID binary, is a specialized type of executable file in Unix-like operating systems. It enables a program to execute with the privileges of the file owner or a specific user/group, rather than inheriting the privileges of the user running the file. The term \u0026ldquo;uid\u0026rdquo; in \u0026ldquo;setuid\u0026rdquo; stands for user ID.\nWhen a setuid binary is executed, it temporarily changes the effective user ID (EUID) of the process to match that of the binary\u0026rsquo;s owner. This allows the process to perform actions or access resources typically restricted to the owner\u0026rsquo;s privileges, effectively elevating the process\u0026rsquo;s privileges for the duration of its execution.\nSetuid binaries find use in system administration tasks and operations requiring elevated privileges, such as managing network interfaces, modifying system files, or accessing sensitive information. Examples include programs like passwd (for changing passwords) and sudo (for executing commands with elevated privileges).\nGiven the potential security risks associated with setuid binaries, strict measures are in place to ensure their safe use. This involves careful programming and thorough testing to prevent unauthorized access or misuse of elevated privileges. System administrators should review and maintain setuid binaries regularly to minimize potential security vulnerabilities.\n","permalink":"https://belwalkarvarad.tech/posts/setuid-binary/","summary":"what is SETUID?","title":"setuid Binary in Linux"},{"categories":["Redis"],"content":"Comprehensive list of redi-cli Commands. Basic Commands SET key value GET key DEL key [key ...] EXISTS key KEYS pattern TTL key EXPIRE key seconds PERSIST key RANDOMKEY FLUSHDB FLUSHALL RENAME oldkey newkey TYPE key String Commands SET key value GET key MSET key value [key value ...] MGET key [key ...] INCR key DECR key APPEND key value Hash Commands HSET key field value HGET key field HMSET key field value [field value ...] HMGET key field [field ...] HDEL key field [field ...] HGETALL key List LPUSH key value [value ...] RPUSH key value [value ...] LPOP key RPOP key LLEN key LRANGE key start stop Set Commands SADD key member [member ...] SREM key member [member ...] SMEMBERS key SISMEMBER key member Configuration CONFIG GET parameter CONFIG SET parameter value Authentication AUTH password ","permalink":"https://belwalkarvarad.tech/posts/redis-cli/","summary":"List of useful redis-cli commands","title":"Redis CLI commands"},{"categories":["SSH","Networking"],"content":"Establishing Encrypted Communication with SSH Tunneling Scenario Overview Consider the following scenario:\nI have access to two PCs in a network full of intruders. A service is running on machine 2, which I need to access from my machine 1, physically located elsewhere. I have root privileges, and SSH is running on machine 2, accessible only with my private key (password authentication turned off). Setting up certificates is cumbersome in client code, making it time-consuming. SSH Tunneling Solution To address the plaintext communication issue, SSH Tunneling can be utilized for encrypted communication between machine 1 and machine 2.\nLocal Forwarding Suppose the command:\nssh -L 8080:localhost:80 user@remotehost This command creates a \u0026ldquo;Local Forwarding\u0026rdquo; of SSH, allowing access to a service on port 80 on the remote host. Requests to machine 1\u0026rsquo;s port 8080 are tunneled to machine 2, establishing a TCP connection to localhost:80.\nReverse SSH Tunnel Suppose the command:\nssh -R 8080:localhost:80 user@remotehost In this \u0026ldquo;Reverse SSH Tunnel,\u0026rdquo; machine 2\u0026rsquo;s port 8080 is tunneled, meaning traffic to machine 2\u0026rsquo;s 8080 port is forwarded to machine 1. The TCP connection is established, and the response is sent back through the tunnel.\nThis is particularly useful for scenarios behind NAT where services need to be exposed to the public.\nHow to Establish Reverse SSH Tunnel Between Two PCs Behind NAT Using Relay Server Prerequisites Relay server\u0026rsquo;s hostname or IP address Your username and password for the relay server On the Machine to Be Accessed Remotely Run:\nssh -N -R 49101:localhost:21001 relayuser@relayhost Explanation:\n-N: Forwards ports only without logging in. 49101: Port on the relay server (adjust if not available). 21001: Port on the remote machine where the service will run. On the Client Machine Run:\nssh -N -L 8080:localhost:49101 relayuser@relayhost Explanation:\n-N: Forwards ports only. 8080: Any request to this port on the client machine will be tunneled to the relay server, creating a TCP connection to port 49101. This workflow establishes a reverse SSH tunnel, allowing secure access to the remote machine\u0026rsquo;s services.\nLogging into Remote Machine Using SSH Through SSH Tunneling No need to change anything on the client side. Just make an SSH connection like this:\nssh -p 8080 username_on_remote_machine@localhost This ensures that traffic is forwarded to port 22 on the remote machine, where SSHD is listening.\n","permalink":"https://belwalkarvarad.tech/posts/reverse-ssh-tunnel/","summary":"create your own tunnel","title":"Reverse SSH Tunnel"},{"categories":["NAT","Networking"],"content":"NAT is by far the most used technology to provide internet access to the public.\nYou might be knowing that Internet Service Providers such as Airtel, AT\u0026amp;T are providing their customers internet through their cellular network infrastructure,\nYes, you heard it right, this was and is the major advantage for them as they can establish both cellular network and internetwork on the same tower which they own, this makes them simplify the implementation of routers which can then provide internet to the public in that region\nBut how does this work?\nYou might be knowing that the private ip ranges are,\n10.0.0.0/8 172.16.0.0/14 this means from 172.16.0.0 to 172.31.255.255 192.168.0.0/16 But what does this mean?\nWell this means that NO RIR i.e Regional Internet Registry NOR the IANA i.e Internet Number Authority can assign or give any ip or network from these ranges to any organisation or to anyone, This means no organisation or anything in the world will own any ip or a network from these ranges as their public endpoint\nBut, understand that we as human beings have assigned these ranges as private ones, the core routers and the provider edge routers don\u0026rsquo;t understand that unless configured specifically, right,\nHere, if any core router or provider edge router has an entry in the routing table for any ip or network from this range, the interface on which the packet has to sent to, must either belong to that network itself, or must be performing subnetting on that network, or you may say that it should be provider edge router outgrowing in that network through the interface which is listed in the routing table.\ndon\u0026rsquo;t consider this as of now,\nwell you know that these are private ranges and most importantly used to just access internet and let me clear, they are not used to provide any service to the outside world, remember i am not talking about any special cases like port forwarding or tunneling, in standared scenario, they are just used to provide internet access to internal network.\nSo what does NAT do?\nIt simply makes request on behalf of you and gets the response back to you, yes that is simple!\nYour ISP makes a private network (mostly, but just focus here) in one of these range, and runs DHCP service on its end, and when you on you internet, you get connectivity right?\nYes, but where is you ethernet port ?\nhow are you even connecting with that router?\nWell, in case of wireless networks, you have virtual interfaces through which you connect, and you smart phone will have one, yes only one, that is why you can either turn network connectivity of airtel or jio, not both right?\nSo this one virtual interface gets the DHCP allocated ip address within a private range, and gets the other network info such as gateway ip, lease time and so on.\nRemember that the interface to which your mobile phone is connected is again the virtual interface of that router, and here, as in physical we require switches, here no switches are required as everything is software based or in the control plane itself.\nHere, switch you may say is nothing but a collection of mappings of which frequency we need to accept and send packets to a particular endpoint and the endpoint itself\nHere, you smartphone also has routing table, now understand, every computer has a routing table,\nwhen you make a request to ip suppose 120.0.2.2/24 Here, you phone doesn\u0026rsquo;t have any routing information in routing table about this network right, i.e about 120.0.2.0/24, So if the phone doesn\u0026rsquo;t know where to send, it sends to the default gateway,\nwith source ip lets say 192.168.2.2 and dest ip of that gateway 192.168.1.1, with source port 51k and dest port 80\nnow when this request comes to the router, the router knows that it has performed NAT (I WILL EXPLAIN HOW IT KNOWS LATER) on this particular interface, so what router does, as it is a provider edge router, it will definitely will be running a BGP protocol with which it can find the next hop for the networks, so when this packet comes on it, it first finds the network to which it belongs and sees if there is any entry in that BGP table or routing table you may say, once it gets the next hop and the ip of next hop, it simply gets a free port from his pool of ports lets say 40k and makes an entry in the NAT table like following (not exactly)\nsource IP Dest IP sourceport destport allo.port 192.168.2.2 120.0.2.2 51k 80 40k this entry persists until it becomes inactive(will discuss later),\nSo what router does, it simply replaces the source ip with the ip address of the interface from which it needs to forward the packet to the next hop, always remember the ip address of that interface only from which it is going to send it to next hop, and the source port to 40k and finally sends it.\nonce it gets the response packet, what does that packet has? it has source ip 120.0.2.2, source port 80, dest ip 29.20.2.4, dest port 40k\nHere the router gets this packet from that interface which is having ip 29.20.2.4, so first time, router might think that this packet is for itself, so there are configuration dependancies whether router will take time to check whether any of its services is listening on the port 40k (which obviously not at all possible) or directly go to NAT table when it finds a packet dedicated for it,\ni think the second case would be true, so any way, when the router sees in the NAT table, if there is not entry according to the dest port of the packet, it discards the packet, yes it discards, and you may say that the indexing of this table is done on the basis of allocated port so if router finds and entry,\nif checks whether the packet is following everything or not, i.e it is coming from the intended destination, the port is correct, and so on, once it is checked, the router simply changes the destination ip to 192.168.2.2 here, and also the destination port to 51k as before, and then it checks in the routing table where to send that packet to, so it finds the interface to which it needs to send,\nhere, if in the routing table, the entry is there for the network which here is indeed private and there is shown the interface to which the packet needs to be sent from, if the next hop ip is MISSING or NULL, i am repeating again, if the NEXT HOP ip is MISSING or NULL, then router checks whether the interface is in the same network or not, and here, the interface is indeed in the same network, so router now checks whether there is any entry for the MAC address for that ip address in its ARP table, if not, it gets from ARP resolution,\nonce get it simply transmitts through that interface meaning it will directly reach to the host and may be throug switches.\nbut if there is subnetting performed, then there will be next hop located in the routing table, and it needs to simply pass on to them,\nnow the routers which are actually part of the complete usable subnet, there will be an empty entry in the next hop, meaning that it has to send directly to the host.\nand yes, in this way the request and response are successful\nhere, the default side effect of this is one cannot from outside can connect to the internal network or hosts directly, as it is obviously not possible, because it seems non-logical that how can outsider can generate such a packet that can go inside, the only possible way is to have session established already i.e in the NAT table there should be entry and only traffic from that server will get through.\nAlso some ISP don\u0026rsquo;t care about these ranges even, in fact, my mobile has got ip address 25.23.14.187 from jio ISP, which means that it really doesn\u0026rsquo;t matter at the router end, why?\nWell, suppose this network is /24, and the interface to which i am connected to i.e gateway is 25.23.14.1/24, now when the router performs NAT and is going to send the packet to the outside, it is going to add the source IP of the interface from which it is going to forward the packet to the next hop, according to NAT policy, and once the response comes it is for the same router i.e with the ip address of that interface, then router first may check if any service wants that packet which is listening on its os, if not, then it will check the NAT table, and there will be the entry then, and according to that entry, it has to send the packet to the interface with ip 25.23.14.1, and if subnetting done, then next hop else NULL, you got the point,\nbut here, don\u0026rsquo;t you think that this is a provider edge router and it also might have entry for the same network for some real world organisation?\nYes, of course, but you need to understand that this is typically done on the routers which are not performing any BGP and so, meaning they do have4 publicly routable ip addresses for some of their interfaces, but not necessarily they participate in routing, i.e they are specifying the default route for to the other routers to send the packets and those routers when got the response, can definitely send it back towards this router, where, NAT is performed and that 25. something network has opening from that interface, so that router doesn\u0026rsquo;t have to go to the its gatway or default route again!\nSo, the concept of gateway or default route is not just used in the private network but also in such scenarios, but yes, this is technique used by ISPs today by allocating single public ip address to their such routers and configuring default route to their main routers which actually participate in BGP topology to exchange routing tables and so on.\n","permalink":"https://belwalkarvarad.tech/posts/nat-overview/","summary":"NAT behind the scenes","title":"How does NAT work?"},{"categories":["Git"],"content":"Git by default uses ~/.ssh/id_rsa to authenticate against remote repository, but doesn\u0026rsquo;t give specific command line option to use another key.\nIf you have multiple remote repositories setup, this can be frustrating, to work around this, you just need to export an env variable like this,\nexport GIT_SSH_COMMAND=\u0026#34;ssh -i /path/to/your/ssh_key\u0026#34; and after this you can happily authenticate against the repository you are intending to, and work with it.\nBut for working with another remote repo, you might need to run above command with other appropriate private key.\n","permalink":"https://belwalkarvarad.tech/posts/ssh-key-for-github/","summary":"custom key to use for git auth.","title":"How to setup custom key for Git to authenticate against remote repo?"},{"categories":["Linux","Cryptography"],"content":"Here are some useful and common commands to use for asymmetric cryptography using gpg. To create new key :\ngpg --full-generate-key To show public keys with their fingerprints:\ngpg --list-keys To show private keys with their fingerprints(same as their associated public keys\u0026rsquo; fingerprints)\ngpg --list-secret-keys To export public key:\ngpg --armor --export \u0026lt;fingerprint\u0026gt; (armor means export in ascii format) To export private key:\ngpg --armor --export-private-keys \u0026lt;fingerprint\u0026gt; To encrypt file with pubkey of one recipient:\ngpg --encrypt --recipient \u0026lt;name or email as per pubkey\u0026gt; file_to_encrypt To encrypt file with pubkey of multiple recipients (follow another file along with this file to understand the workflow)\ngpg --encrypt --recipient \u0026lt;r1\u0026gt; --recipient \u0026lt;r2\u0026gt; --recipient \u0026lt;r3\u0026gt; file_to_encrypt To decrypt the file with the private key ( Please note that there is always associated a metadata with the file which tells the key id i.e name or email so gnupg takes only that)\n(private key which matches the metadata, if it doesn\u0026rsquo;t find it returns error that it cannot decode)\ngpg --decrypt file_to_decrypt To get keygrip:\ngpg --list-keys --with-keygrip To get in machine readable format:\ngpg --list-keys --with-colons To delete a key-pair, you first need to delete the private key:\ngpg --delete-secret-keys \u0026lt;name or email or fingerprint\u0026gt; Then delete the public key:\ngpg --delete-key \u0026lt;name or email or fingerprint\u0026gt; To import a key (doesn\u0026rsquo;t matter whether it is public key or private key)\ngpg --import \u0026lt;key_file\u0026gt; To dearmor a .asc key, i.e key in ascii format do this :\nsudo gpg -o \u0026lt;path_to_outout_key.gpg\u0026gt; .asc_key --dearmor (NOTE: NEVER CREATE KEYS WITH SAME NAME OR EMAIL, THIS CAN MAKE BIG PROBLEMS WHILE USING OR DELETING THE KEYS)\n","permalink":"https://belwalkarvarad.tech/posts/gpg-asymmetric-crypt-commands/","summary":"gpg commands for assymetric cryptography","title":"Assymetric Cryptography using GPG"},{"categories":["Linux","Cryptography"],"content":"Symmetric keys To encrypt the file with passphrase:\ngpg --symmetric file_to_encrypt This will prompt you for the passphrase to enter to encrypt the file,\nTo strongly encrypt, create first a symmetric key and use this as passphrase\nTo decrypt simply run, and give passphrase when prompted:\ngpg --decrypt file_to_decrypt Here gpg will know whether to use symmetric or asymmtric decryption here\nHere gpg after taking the passphrase, uses a key-derivation-function(kdf) to derive a key from the passphrase and use that key to encrypt the file\nKey Distribution The process of making your key publicly available on a keyserver is coupled with an important security measure - email authorization. Upon upload, the keyserver sends an email to the associated address with a link for authorization. Clicking on this link is mandatory for the key to be accessible to others for search and download, primarily based on email search.\nThis approach not only ensures the legitimacy of key ownership but also safeguards against attempts to manipulate key distribution for malicious purposes. The email authorization step adds an extra layer of protection, making the key distribution process more resilient against potential threats.\nTo send the publickey to the key-server:\ngpg --keyserver \u0026lt;keyserverurl\u0026gt; --send-keys \u0026lt;fingerprint\u0026gt; For example:\ngpg --keyserver hkps://keys.openpgp.org --send-keys \u0026lt;fingerprint\u0026gt; Now to search for a key on keyserver: (NOTE: Reflection of uploaded publickey takes some time)\ngpg --keyserver hkps://keys.openpgp.org --search-keys \u0026lt;username or email\u0026gt; Once you find the key on the keyserver, along with the metadata, it will also show the fingerprint for that key, So to download that public key:\ngpg --keyserver hkps://keys.openpgp.org --recv-keys \u0026lt;fingerprint\u0026gt; Also other than openpgp,\nwe have pgp.mit.edu keyserver available so you can change above url to, [hkp://pgp.mit.edu]\nEdit key expiration To edit the key expiration date, run:\ngpg --edit-key \u0026lt;key fingerprint or name or email\u0026gt; You will get gpg prompt\ngpg\u0026gt; run expire\ngpg\u0026gt; expire and then choose option make sure to run save\ngpg\u0026gt; save DONE\nMultiple Recipents When you run the following command:\ngpg --encrypt --recipent \u0026lt;recipent name or email as per pubkey\u0026gt; file_to_encrypt here there is only single recipient, so the gpg will directly encrypt the file with the public key of the recipient and create a .gpg file\nbut supppose you give multiple recipients like this:\ngpg --encrypt --recipient \u0026lt;r1\u0026gt; --recipient \u0026lt;r2\u0026gt; --recipient \u0026lt;r3\u0026gt; file_to_encrypt Here the gpg first, creates a symmetric key and encrypts the file, and then encrypts the symmetric key each with public key of the recipient so if there are 3 recipients 3 encrypted symmetric keys will get created and they are going to get appended to the encrypted file along with their metadata\nSigning and Verification To sign a file\ngpg --sign file To verify a file\ngpg --verify file ","permalink":"https://belwalkarvarad.tech/posts/gpg-other-content/","summary":"important topics covered","title":"gpg: symmetric-cryptography, key distribution and more..."},{"categories":["JWT","Authentication","REST"],"content":"JSON Web Tokens (JWT) Introduction JWT.io\nJSON Web Tokens (JWTs) are commonly passed in the Authorization header of an HTTP request. The Authorization header is used to send authentication information to the server, and JWTs are a common way to authenticate requests.\nIt is also possible to pass a JWT in the body of a request, although this is not as common. To do this, you can include the JWT in the request body as a string and set the Content-Type header to \u0026ldquo;application/jwt\u0026rdquo;. However, keep in mind that most servers expect JWTs to be passed in the Authorization header and may not support passing them in the body.\nWorking When the server creates a new JWT token, it takes the token information (header) and claims (payload) and combines them with a secret key to generate a signature. This signature is included as the last part of the JWT token (signature), and the token is sent to the client.\nWhen the client sends a request to the server, it includes the JWT token in the request headers. The server then decodes the token, which separates the header, payload, and signature. The server uses the same secret key that it used to create the token and the algorithm to generate a new signature from the header and payload. If the newly generated signature matches the signature included in the token, it means that the token has not been tampered with, and the server can proceed with the request.\n// Authorization is one of the headers available in the HTTP request // Authorization -----------\u0026gt; \u0026#34;Bearer \u0026lt;JWT-Token\u0026gt;\u0026#34; // This indicates the authorization method, which is JWT After the user login, a user token is generated, which will look like this:\n\u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\u0026#34;. It consists of three parts, each separated with a dot(.). The first part is the header, which is Base64 encoded. After decoding, we get something like:\n{ \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;, // Algorithm used \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } The second part is the claims and is Base64 encoded. After decoding, we get something like:\n{ \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;, \u0026#34;admin\u0026#34;: true } The third part is the signature and is generated with:\nHMACSHA256( base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), *secret base64 encoded* ) ","permalink":"https://belwalkarvarad.tech/posts/jwt/","summary":"The authentication backbone","title":"JWT working Explained!"},{"categories":["Programming","Go"],"content":"Managing Dependencies in Go In Go, managing dependencies differs from Python\u0026rsquo;s virtual environments. In Go, all project dependencies are stored in the src directory within the GOPATH for Windows, and pkg/mod for Linux. This structure is organized by import paths. If multiple projects share dependencies, you might end up with conflicting versions.\nGo Modules Introduced in Go 1.11, Go modules provide a flexible way to manage dependencies and avoid conflicts. Each project defines its dependencies in a go.mod file in the project\u0026rsquo;s root directory.\nThe go.mod file specifies import paths, versions, and additional dependencies. This isolation helps prevent conflicts between different projects.\nProject Initialization When starting a new Go project:\nSet GOROOT (Go installation directory) and add $GOROOT/bin/ to PATH. Set GOPATH (workspace) to /home/foo_user/go/ for Linux and C:\\Users\\foo_user\\go\\ for Windows. Optionally set GOBIN to $GOPATH/bin. Working on Projects Create an empty project directory, e.g., /home/foo_user/go_project. Write Go code in this directory or use existing standard libraries. For external dependencies, initialize the project with go mod init github.com/foo_user/some_name. Use go get to download and install dependencies, ensuring they are listed in the go.mod file. Go Install The go install command builds and installs necessary files into the right location. For example:\ngo install path_to_file/go_executable.go This command compiles dependencies and copies the executable to the project\u0026rsquo;s bin folder.\nGo Workflow vs. Node.js and Python Comparing Go\u0026rsquo;s workflow:\nGo lacks a local node_modules equivalent or a system like Python virtual environments. Dependencies for different projects share the same directory ($GOPATH/src/ for Windows, $GOPATH/pkg/mod/ for Linux). Similar to having a single node_modules folder in your home directory for Node.js. Resolving dependencies is reliant on the go.mod file, analogous to Python\u0026rsquo;s requirements.txt or pipenv. Understanding Key Go Environment Terminologies GOROOT: Go installation directory. GOPATH: Workspace where projects and dependencies are stored (src for Windows, pkg/mod for Linux). GOBIN: Optional, points to $GOPATH/bin/. Project initiation involves setting up these variables and creating a go.mod file. Dependency Resolution Dependencies must be listed in the go.mod file for Go to locate them. Importing a package not listed in go.mod will result in an error. The compiler first looks in the local directory, then in system libraries, and finally in the $GOPATH/src/ or $GOPATH/pkg/mod/ directory. ","permalink":"https://belwalkarvarad.tech/posts/golang-workflow/","summary":"Package management in Go","title":"How Go handles packages?"},{"categories":["MySQL"],"content":"Understanding MySQL Storage Engines To examine the variety of storage engines utilized by MySQL, a SQL query against the information_schema database provides insightful results. Consider the following example query:\nSELECT ENGINE FROM information_schema.ENGINES WHERE SUPPORT = \u0026#39;YES\u0026#39;; MySQL employs several commonly used storage engines, each tailored for specific advantages and use cases. Here, we highlight some of the most renowned and widely adopted storage engines:\nInnoDB: InnoDB stands as the default and predominant storage engine in MySQL. Renowned for its robust support of ACID transactions, foreign key constraints, and row-level locking, InnoDB excels in reliability, crash recovery, and scalability. It is ideal for general-purpose applications and is particularly recommended for scenarios demanding transactional support.\nMyISAM: A pioneer among MySQL storage engines, MyISAM is recognized for its simplicity and high performance, especially in read-intensive workloads. With additional capabilities for full-text search, MyISAM is often chosen for non-transactional applications such as data warehousing, logging, or caching. Notably, it lacks support for transactions and referential integrity constraints.\nMemory (HEAP): The Memory storage engine facilitates exceptionally fast read and write operations by storing data in memory. However, due to its in-memory nature, data persistence is not guaranteed and will be lost upon server restart. This engine proves beneficial for temporary data, caching, or high-speed data processing.\nCSV: The CSV storage engine organizes data in comma-separated values (CSV) format, enhancing compatibility with applications that consume CSV files. While useful for importing or exporting data in a simple and portable format, CSV lacks advanced features such as indexing or transactions.\nArchive: Optimized for rapid insertions and efficient storage of large datasets, the Archive storage engine is suitable for write-intensive applications or archiving historical data. Retrieval speed is less critical in scenarios where large-scale data storage is a priority.\nNDB (Cluster): Designed for MySQL Cluster, the NDB storage engine offers distributed, high-availability capabilities with synchronous replication and automatic data partitioning across multiple nodes. Recognized for its scalability and fault tolerance, NDB is well-suited for demanding, high-availability applications.\n","permalink":"https://belwalkarvarad.tech/posts/mysql-storage-engines/","summary":"Different storage engines to use","title":"MySQL storage engines"},{"categories":["Linux","Networking"],"content":"When you run ip a in your terminal, you get something like this,\nwlo1: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 3c:55:76:1b:e3:03 brd ff:ff:ff:ff:ff:ff altname wlp3s0 inet 192.168.219.8/24 brd 192.168.219.255 scope global dynamic noprefixroute wlo1 valid_lft 2466sec preferred_lft 2466sec inet6 2409:4042:2c85:9bce:4425:fcde:9b5a:cbfd/64 scope global temporary dynamic valid_lft 1866sec preferred_lft 1866sec inet6 2409:4042:2c85:9bce:c6ef:6241:395a:a53b/64 scope global dynamic mngtmpaddr noprefixroute valid_lft 1866sec preferred_lft 1866sec inet6 fe80::fe03:1ae9:17a9:163e/64 scope link noprefixroute valid_lft forever preferred_lft forever This output is showing the network interface named \u0026ldquo;wlo1\u0026rdquo; and its current configuration. Here\u0026rsquo;s what each thing represents:\nconf Description wlo1: This is the name of the network interface. \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt;: These are the flags indicating the current state of the interface. In this case, it\u0026rsquo;s up and running, and able to send and receive broadcast messages. mtu 1500: This is the maximum transmission unit (MTU) for this interface, which is the largest packet size it can handle. qdisc noqueue: This indicates that there is no queuing discipline set up for this interface. state UP: This indicates that the interface is currently active and able to send and receive packets. group default: This indicates the group that this interface belongs to. qlen 1000: This is the maximum length of the transmit queue for this interface. link/ether 3c:55:76:1b:e3:03 brd ff:ff:ff:ff:ff:ff: This is the MAC address of the interface and the broadcast MAC address. altname wlp3s0: This is an alternate name for the interface. inet 192.168.219.8/24: This is the IPv4 address assigned to the interface. In this case, it\u0026rsquo;s a dynamic address assigned through DHCP, and the subnet mask is /24. brd 192.168.219.255: This is the broadcast address for the network that the interface is on. scope global: This indicates that this IP address is a global IP address that can be reached from anywhere on the network. dynamic noprefixroute: This indicates that this is a dynamic IP address assigned through DHCP, and that there is no specific route set up for it. valid_lft 2466sec preferred_lft 2466sec: These are the valid and preferred lifetimes for the IPv4 address. In this case, the address will expire in 2466 seconds, and it\u0026rsquo;s the preferred address until it expires. inet6: These are the IPv6 addresses assigned to the interface. fe80::fe03:1ae9:17a9:163e/64: This is the link-local IPv6 address for the interface. scope link noprefixroute: This indicates that this is a link-local address, and that there is no specific route set up for it. ","permalink":"https://belwalkarvarad.tech/posts/output-of-ip-a/","summary":"ip addr basics","title":"ip addr basics"},{"categories":["tmux","Configuration","Productivity"],"content":"Following is the tmux.conf file I normally use # Bind Alt+j to move to the previous window bind-key -n M-j select-window -p # Bind Alt+l to move to the next window bind-key -n M-l select-window -n # Bind Alt+i to switch to the previous session bind-key -n M-i switch-client -p # Bind Alt+k to switch to the next session bind-key -n M-k switch-client -n # Bind Alt+c to create a new window bind-key -n M-f new-window # Bind Alt+r to rename the current window bind-key -n M-r command-prompt -I \u0026#34;#W\u0026#34; \u0026#34;rename-window \u0026#39;%%\u0026#39;\u0026#34; # Bind Alt+s to rename the current session bind-key -n M-s command-prompt -I \u0026#34;#S\u0026#34; \u0026#34;rename-session \u0026#39;%%\u0026#39;\u0026#34; # Bind Alt+d to detach the current session bind-key -n M-d detach-client # Create vertical pane (alt+v) bind-key -n M-v split-window -h # Create horizontal pane ( alt+h) bind-key -n M-h split-window -v # Go to left pane (goes to extreme right when at extreme left) (alt+ ,) bind-key -n M-, select-pane -L # Go to upper pane (goes to bottom when at top) (alt+ .) bind-key -n M-. select-pane -U # Swap current window with next window (alt+g) bind-key -n M-g swap-window -t :+ # Swap current window with previous window ( alt+n) bind-key -n M-n swap-window -t :- # Run alt+q to clear the tmux history ( equivalent to tmux clear-history) bind -n M-q send-keys -R Enter \\; clear-history # Enable mouse scrolling set-option -g mouse on setw -g mode-keys vi Simple and easy to learn key bindings for this tmux config. Description Command Create new window alt+f Go to previous window alt+j Go to next window alt+l Detach current session alt+d Rename current window alt+r Rename current session alt+s Go to next session alt+k Go to previous session alt+i Create horizontal pane alt+h Create vertical pane alt+v Go to left pane alt+, Go to right pane alt+. Go to upper pane alt+g Go to below pane alt+n Copying Content: To initiate copying, use Ctrl + B as the starting command. Navigate to the content by pressing [ and utilize arrow keys for precise selection. Press SPACE to begin selecting the desired text. Upon completion, press ENTER to confirm the selection. Alternative Method: Scroll through the content using the mouse. Select the text by holding down the mouse click. Release the mouse click to return to the original prompt with the text now copied. Pasting Content: For pasting, press Ctrl + B to activate the tmux command. Press ] to paste the previously copied text. Copy to clipboard This is the tmux buffer which you are using, i.e when you run above commands, the data is copied to tmux buffer, to copy this content to your system\u0026rsquo;s clipboard, just enter following command while in tmux session:\ntmux show-buffer | xclip -selection clipboard Using Tmux in Windows To use tmux in windows, first install any distro of your choice on WSL, once installed, install tmux according to the distribution\u0026rsquo;s docs,\nand after that, simply start it.\nYou may ask i want the tmux to be working in windows environment right?\nWell it is pretty simple, simply run powershell.exe in the terminal and woh!\nPowershell with windows info just got up right,\nnow simply do cd C: and yup, you got into windows file system!\nNow you can use tmux in windows as if you are running it in windows itself.\n","permalink":"https://belwalkarvarad.tech/posts/my-tmux-conf/","summary":"Make your life easy using tmux :)","title":"My tmux configuration"}]